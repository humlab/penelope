from __future__ import annotations

import abc
import csv
import zipfile
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Sequence, Set, Union

import pandas as pd

from penelope.utility import FilenameFieldSpecs, PropertyValueMaskingOpts, PropsMixIn

# pylint: disable=too-many-instance-attributes

TextSource = Union[str, zipfile.ZipFile, List, Any]

FilenameFilterSpec = Union[Callable, Sequence[str]]

GLOBAL_TF_THRESHOLD_MASK_TOKEN: str = "__low-tf__"


@dataclass
class TextReaderOpts(PropsMixIn["TextReaderOpts"]):
    filename_pattern: str = field(default="*.txt")
    filename_filter: Optional[FilenameFilterSpec] = None
    filename_fields: Optional[FilenameFieldSpecs] = None
    index_field: Optional[str] = None
    as_binary: Optional[bool] = False
    sep: Optional[str] = field(default='\t')
    quoting: Optional[int] = csv.QUOTE_NONE
    n_processes: int = 1
    n_chunksize: int = 2
    dehyphen_expr: str = field(default=r"\b(\w+)[-Â¬]\s*\r?\n\s*(\w+)\s*\b")

    def copy(self, **kwargs) -> TextReaderOpts:
        return TextReaderOpts(**{**self.props, **kwargs})


PhraseSubstitutions = Union[Dict[str, List[str]], List[List[str]]]


@dataclass
class ExtractTaggedTokensOpts:
    lemmatize: Optional[bool] = None

    text_column: str = 'token'
    lemma_column: str = 'baseform'
    pos_column: str = 'pos'

    target_override: Optional[str] = None

    """ These PoS define the tokens of interest """
    pos_includes: str = ''

    """ These PoS are always removed """
    pos_excludes: str = ''

    """ These PoS define tokens that are replaced with a dummy marker `*` """
    pos_paddings: Optional[str] = ''
    pos_replace_marker: str = '*'

    passthrough_tokens: List[str] = field(default_factory=list)
    append_pos: bool = False

    phrases: Optional[PhraseSubstitutions] = None

    """Tokens that will be filtered out"""
    block_tokens: List[str] = field(default_factory=list)

    # block_chars: str = ""

    """Global term frequency threshold"""
    global_tf_threshold: int = 1

    """Global term frequency threshold"""
    global_tf_threshold_mask: bool = False

    filter_opts: Union[PropertyValueMaskingOpts, dict] = field(default_factory=PropertyValueMaskingOpts)

    def __post_init__(self):
        self.filter_opts = (
            PropertyValueMaskingOpts(**self.filter_opts)
            if isinstance(self.filter_opts, dict)
            else self.filter_opts or PropertyValueMaskingOpts()
        )

    @property
    def target_column(self) -> str:
        if self.target_override:
            return self.target_override
        return self.lemma_column if self.lemmatize else self.text_column

    def get_pos_includes(self) -> Set[str]:
        return set(self.pos_includes.strip('|').split('|')) if self.pos_includes else set()

    def get_pos_excludes(self) -> Set[str]:
        return set(self.pos_excludes.strip('|').split('|')) if self.pos_excludes is not None else set()

    def get_pos_paddings(self) -> Set[str]:
        return (
            set(x for x in self.pos_paddings.strip('|').split('|') if x != '')
            if self.pos_paddings is not None
            else set()
        )

    def get_passthrough_tokens(self) -> Set[str]:
        if self.passthrough_tokens is None:
            return set()
        return set(self.passthrough_tokens)

    def get_block_tokens(self) -> Set[str]:
        if self.block_tokens is None:
            return set()
        return set(self.block_tokens)

    def clear_tf_threshold(self) -> ExtractTaggedTokensOpts:
        self.global_tf_threshold = 1
        return self

    @property
    def props(self):
        return dict(
            lemmatize=self.lemmatize,
            target_override=self.target_override,
            pos_includes=self.pos_includes,
            pos_excludes=self.pos_excludes,
            pos_paddings=self.pos_paddings,
            pos_replace_marker=self.pos_replace_marker,
            passthrough_tokens=list(self.passthrough_tokens or []),
            block_tokens=list(self.block_tokens or []),
            append_pos=self.append_pos,
            phrases=None if self.phrases is None else list(self.phrases),
            text_column=self.text_column,
            lemma_column=self.lemma_column,
            pos_column=self.pos_column,
            filter_opts=self.filter_opts.props,
        )

    def ingest(self, opts: dict) -> ExtractTaggedTokensOpts:
        self.pos_includes = opts.get('pos_includes', self.pos_includes)
        self.pos_paddings = opts.get('pos_paddings', self.pos_paddings)
        self.pos_excludes = opts.get('pos_excludes', self.pos_excludes)
        self.lemmatize = opts.get('lemmatize', self.lemmatize)
        self.phrases = opts.get('phrases', self.phrases)
        self.append_pos = opts.get('append_pos', self.append_pos)
        self.global_tf_threshold = opts.get('tf_threshold', self.global_tf_threshold)
        self.global_tf_threshold_mask = opts.get('tf_threshold_mask', self.global_tf_threshold_mask)
        return self

    def set_numeric_names(self) -> ExtractTaggedTokensOpts:
        self.pos_column = "pos_id"
        self.lemma_column = "lemma_id"
        self.text_column = "token_id"
        return self

    @property
    def has_effect(self) -> bool:
        if self.pos_includes or self.pos_paddings or self.pos_excludes:
            return True
        if self.phrases:
            return True
        if self.append_pos:
            return True
        if self.global_tf_threshold > 1:
            return True
        return False

    @property
    def of_no_effect(self) -> bool:
        return not self.has_effect


class ICorpusReader(abc.ABC):
    @property
    @abc.abstractproperty
    def filenames(self) -> List[str]:
        return None

    @property
    @abc.abstractproperty
    def metadata(self) -> List[Dict[str, Any]]:
        return None

    @property
    def document_index(self) -> pd.DataFrame:
        return None

    @abc.abstractmethod
    def __next__(self):
        'Return the next item from the iterator. When exhausted, raise StopIteration'
        raise StopIteration

    @abc.abstractmethod
    def __iter__(self) -> "ICorpusReader":
        return self
